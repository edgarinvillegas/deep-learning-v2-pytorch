{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Student Admissions with Neural Networks\n",
    "In this notebook, we predict student admissions to graduate school at UCLA based on three pieces of data:\n",
    "- GRE Scores (Test)\n",
    "- GPA Scores (Grades)\n",
    "- Class rank (1-4)\n",
    "\n",
    "The dataset originally came from here: http://www.ats.ucla.edu/\n",
    "\n",
    "## Loading the data\n",
    "To load the data and format it nicely, we will use two very useful packages called Pandas and Numpy. You can read on the documentation here:\n",
    "- https://pandas.pydata.org/pandas-docs/stable/\n",
    "- https://docs.scipy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading the csv file into a pandas DataFrame\n",
    "data = pd.read_csv('student_data.csv')\n",
    "\n",
    "# Printing out the first 10 rows of our data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   admit   400 non-null    int64  \n",
      " 1   gre     400 non-null    int64  \n",
      " 2   gpa     400 non-null    float64\n",
      " 3   rank    400 non-null    int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 12.6 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa       rank\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data\n",
    "\n",
    "First let's make a plot of our data to see how it looks. In order to have a 2D plot, let's ingore the rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to help us plot\n",
    "def plot_points(data):\n",
    "    X = np.array(data[[\"gre\",\"gpa\"]])\n",
    "    y = np.array(data[\"admit\"])\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
    "    plt.xlabel('Test (GRE)')\n",
    "    plt.ylabel('Grades (GPA)')\n",
    "    \n",
    "# Plotting the points\n",
    "plot_points(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly, it looks like the students with high scores in the grades and test passed, while the ones with low scores didn't, but the data is not as nicely separable as we hoped it would. Maybe it would help to take the rank into account? Let's make 4 plots, each one for each rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the ranks\n",
    "data_rank1 = data[data[\"rank\"]==1]\n",
    "data_rank2 = data[data[\"rank\"]==2]\n",
    "data_rank3 = data[data[\"rank\"]==3]\n",
    "data_rank4 = data[data[\"rank\"]==4]\n",
    "\n",
    "# Plotting the graphs\n",
    "plot_points(data_rank1)\n",
    "plt.title(\"Rank 1\")\n",
    "plt.show()\n",
    "plot_points(data_rank2)\n",
    "plt.title(\"Rank 2\")\n",
    "plt.show()\n",
    "plot_points(data_rank3)\n",
    "plt.title(\"Rank 3\")\n",
    "plt.show()\n",
    "plot_points(data_rank4)\n",
    "plt.title(\"Rank 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks more promising, as it seems that the lower the rank, the higher the acceptance rate. Let's use the rank as one of our inputs. In order to do this, we should one-hot encode it.\n",
    "\n",
    "## TODO: One-hot encoding the rank\n",
    "Use the `get_dummies` function in pandas in order to one-hot encode the data.\n",
    "\n",
    "Hint: To drop a column, it's suggested that you use `one_hot_data`[.drop( )](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0      0  380  3.61       0       0       1       0\n",
       "1      1  660  3.67       0       0       1       0\n",
       "2      1  800  4.00       1       0       0       0\n",
       "3      1  640  3.19       0       0       0       1\n",
       "4      0  520  2.93       0       0       0       1\n",
       "5      1  760  3.00       0       1       0       0\n",
       "6      1  560  2.98       1       0       0       0\n",
       "7      0  400  3.08       0       1       0       0\n",
       "8      1  540  3.39       0       0       1       0\n",
       "9      0  700  3.92       0       1       0       0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:  Make dummy variables for rank and concat existing columns\n",
    "rank_dummies = pd.get_dummies(data['rank'], prefix='rank')\n",
    "one_hot_data = data.join(rank_dummies)\n",
    "\n",
    "# TODO: Drop the previous rank column\n",
    "one_hot_data = one_hot_data.drop(columns='rank')\n",
    "\n",
    "# Print the first 10 rows of our data\n",
    "one_hot_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Scaling the data\n",
    "The next step is to scale the data. We notice that the range for grades is 1.0-4.0, whereas the range for test scores is roughly 200-800, which is much larger. This means our data is skewed, and that makes it hard for a neural network to handle. Let's fit our two features into a range of 0-1, by dividing the grades by 4.0, and the test score by 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.7325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre     gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0      0  0.475  0.9025       0       0       1       0\n",
       "1      1  0.825  0.9175       0       0       1       0\n",
       "2      1  1.000  1.0000       1       0       0       0\n",
       "3      1  0.800  0.7975       0       0       0       1\n",
       "4      0  0.650  0.7325       0       0       0       1\n",
       "5      1  0.950  0.7500       0       1       0       0\n",
       "6      1  0.700  0.7450       1       0       0       0\n",
       "7      0  0.500  0.7700       0       1       0       0\n",
       "8      1  0.675  0.8475       0       0       1       0\n",
       "9      0  0.875  0.9800       0       1       0       0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a copy of our data\n",
    "processed_data = one_hot_data[:]\n",
    "\n",
    "# TODO: Scale the columns\n",
    "processed_data['gre'] = processed_data['gre'] / 800\n",
    "processed_data['gpa'] = processed_data['gpa'] / 4\n",
    "\n",
    "# Printing the first 10 rows of our procesed data\n",
    "processed_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test our algorithm, we'll split the data into a Training and a Testing set. The size of the testing set will be 10% of the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is 360\n",
      "Number of testing samples is 40\n",
      "     admit    gre     gpa  rank_1  rank_2  rank_3  rank_4\n",
      "172      0  0.850  0.8700       0       0       1       0\n",
      "137      0  0.875  1.0000       0       0       1       0\n",
      "126      1  0.750  0.8850       1       0       0       0\n",
      "94       1  0.825  0.8600       0       1       0       0\n",
      "72       0  0.600  0.8475       0       0       0       1\n",
      "33       1  1.000  1.0000       0       0       1       0\n",
      "380      0  0.875  0.9125       0       1       0       0\n",
      "223      0  1.000  0.8675       0       0       1       0\n",
      "307      0  0.725  0.8775       0       1       0       0\n",
      "227      0  0.675  0.7550       0       0       0       1\n",
      "     admit    gre     gpa  rank_1  rank_2  rank_3  rank_4\n",
      "20       0  0.625  0.7925       0       0       1       0\n",
      "21       1  0.825  0.9075       0       1       0       0\n",
      "48       0  0.550  0.6200       0       0       0       1\n",
      "50       0  0.800  0.9650       0       0       1       0\n",
      "54       0  0.825  0.8350       0       0       1       0\n",
      "58       0  0.500  0.9125       0       1       0       0\n",
      "87       0  0.750  0.8700       0       1       0       0\n",
      "99       0  0.500  0.8275       0       0       1       0\n",
      "130      1  0.775  0.7925       0       1       0       0\n",
      "134      0  0.700  0.7375       0       1       0       0\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
    "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into features and targets (labels)\n",
    "Now, as a final step before the training, we'll split the data into features (X) and targets (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gre     gpa  rank_1  rank_2  rank_3  rank_4\n",
      "172  0.850  0.8700       0       0       1       0\n",
      "137  0.875  1.0000       0       0       1       0\n",
      "126  0.750  0.8850       1       0       0       0\n",
      "94   0.825  0.8600       0       1       0       0\n",
      "72   0.600  0.8475       0       0       0       1\n",
      "33   1.000  1.0000       0       0       1       0\n",
      "380  0.875  0.9125       0       1       0       0\n",
      "223  1.000  0.8675       0       0       1       0\n",
      "307  0.725  0.8775       0       1       0       0\n",
      "227  0.675  0.7550       0       0       0       1\n",
      "172    0\n",
      "137    0\n",
      "126    1\n",
      "94     1\n",
      "72     0\n",
      "33     1\n",
      "380    0\n",
      "223    0\n",
      "307    0\n",
      "227    0\n",
      "Name: admit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features = train_data.drop('admit', axis=1)\n",
    "targets = train_data['admit']\n",
    "features_test = test_data.drop('admit', axis=1)\n",
    "targets_test = test_data['admit']\n",
    "\n",
    "print(features[:10])\n",
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the 1-layer Neural Network\n",
    "The following function trains the 1-layer neural network.  \n",
    "First, we'll write some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "# log loss error formula\n",
    "def error_formula(y, output):\n",
    "    return - y*np.log(output) - (1 - y) * np.log(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Backpropagate the error\n",
    "Now it's your turn to shine. Write the error term. Remember that this is given by the equation $$ (y-\\hat{y})x $$ for binary cross entropy loss function and \n",
    "$$ (y-\\hat{y})\\sigma'(x)x $$ for mean square error. \n",
    "\n",
    "*Yo: Creo q para MSE debería ser:* $$ (y-\\hat{y})\\sigma'(h)x $$\n",
    "\n",
    "*Yo 2: En realidad los error terms no deberían tener la x, según yo*\n",
    "\n",
    "NOTA: Según entendí, el error term no involucra la x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write the error term formula for LOG LOSS\n",
    "def error_term_formula(x, y, output):\n",
    "    return (y - output) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network hyperparameters\n",
    "epochs = 1000\n",
    "# learnrate = 0.0001\n",
    "learnrate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(features, targets, epochs, learnrate, error_term_formula, error_formula):\n",
    "    '''\n",
    "    Training function\n",
    "    \n",
    "    :param features: size(m,n)\n",
    "    :param targets: size(m,)\n",
    "    :param epochs: int\n",
    "    :param learnrate: float\n",
    "    :param error_term_formula: func(x, y, output)\n",
    "    :param error_formula: func(y, output)\n",
    "    :return: weights size(n,)\n",
    "    '''\n",
    "    \n",
    "    # Use to same seed to make debugging easier\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features, targets):\n",
    "            # Loop through all records, x is the input, y is the target\n",
    "\n",
    "            # Activation of the output unit\n",
    "            #   Notice we multiply the inputs and the weights here \n",
    "            #   rather than storing h as a separate variable \n",
    "            output = sigmoid(np.dot(x, weights))\n",
    "\n",
    "            # The error term\n",
    "            error_term = error_term_formula(x, y, output)\n",
    "\n",
    "            # The gradient descent step, the error times the gradient times the inputs\n",
    "            del_w += error_term\n",
    "            ##weights += learnrate * error_term\n",
    "            \n",
    "\n",
    "        # Update the weights here. The learning rate times the \n",
    "        # change in weights\n",
    "        # don't have to divide by n_records since it is compensated by the learning rate\n",
    "        weights += learnrate * del_w / n_records  \n",
    "\n",
    "        # Printing out the mean square error on the training set\n",
    "        if e % (epochs / 10) == 0:\n",
    "            out = sigmoid(np.dot(features, weights))\n",
    "            loss = np.mean(error_formula(targets, out))\n",
    "            print(\"Epoch:\", e)\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            print(\"=========\")\n",
    "    print(\"Finished training!\")\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss:  0.7484594807897331\n",
      "=========\n",
      "Epoch: 100\n",
      "Train loss:  0.6822223118434836\n",
      "=========\n",
      "Epoch: 200\n",
      "Train loss:  0.6504986565042005\n",
      "=========\n",
      "Epoch: 300\n",
      "Train loss:  0.6349416381190033\n",
      "=========\n",
      "Epoch: 400\n",
      "Train loss:  0.6269223747121504\n",
      "=========\n",
      "Epoch: 500\n",
      "Train loss:  0.6224764463153829\n",
      "=========\n",
      "Epoch: 600\n",
      "Train loss:  0.6197691795949172\n",
      "=========\n",
      "Epoch: 700\n",
      "Train loss:  0.6179372566980591\n",
      "=========\n",
      "Epoch: 800\n",
      "Train loss:  0.6165668293386073\n",
      "=========\n",
      "Epoch: 900\n",
      "Train loss:  0.6154556764330879\n",
      "=========\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "# Train with LOG LOSS\n",
    "weights = train_nn(features.to_numpy(), targets.to_numpy(), epochs, learnrate, error_term_formula, error_formula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss:  0.276566848699054\n",
      "=========\n",
      "Epoch: 100\n",
      "Train loss:  0.2668909245580549\n",
      "=========\n",
      "Epoch: 200\n",
      "Train loss:  0.25859575393181344\n",
      "=========\n",
      "Epoch: 300\n",
      "Train loss:  0.25154929027824297\n",
      "=========\n",
      "Epoch: 400\n",
      "Train loss:  0.24560435077011936\n",
      "=========\n",
      "Epoch: 500\n",
      "Train loss:  0.24061255553365477\n",
      "=========\n",
      "Epoch: 600\n",
      "Train loss:  0.2364334876612602\n",
      "=========\n",
      "Epoch: 700\n",
      "Train loss:  0.23293985824626853\n",
      "=========\n",
      "Epoch: 800\n",
      "Train loss:  0.23001972655101188\n",
      "=========\n",
      "Epoch: 900\n",
      "Train loss:  0.22757676757226153\n",
      "=========\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "# Train with MSE\n",
    "def error_term_formula_mse(x, y, output):    \n",
    "    return (y - output) * output * (1 - output) * x\n",
    "    \n",
    "def error_formula_mse(y, output):\n",
    "    # return np.mean((output - y) ** 2)\n",
    "    return (output - y) ** 2\n",
    "\n",
    "weights = train_nn(features.to_numpy(), targets.to_numpy(), epochs, learnrate, error_term_formula_mse, error_formula_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn_vectorial(features, targets, epochs, learnrate, error_term_formula, error_formula):\n",
    "    '''\n",
    "    Training function, vectorial implementation\n",
    "    \n",
    "    :param features: size(m,n)\n",
    "    :param targets: size(m,)\n",
    "    :param epochs: int\n",
    "    :param learnrate: float\n",
    "    :param error_term_formula: func(x, y, output)\n",
    "    :param error_formula: func(y, output)\n",
    "    :return: weights size(n,)\n",
    "    '''\n",
    "    \n",
    "    # Use to same seed to make debugging easier\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "    for e in range(epochs):        \n",
    "        # Activation of the output unit\n",
    "        #   Notice we multiply the inputs and the weights here \n",
    "        #   rather than storing h as a separate variable \n",
    "        # s(n,)\n",
    "        outputs = sigmoid(np.dot(features, weights))        \n",
    "        # The gradient descent step, the error times the gradient times the inputs        \n",
    "        # (n, m)        \n",
    "        error_terms = error_term_formula(features, targets, outputs)\n",
    "        \n",
    "        # (m, ) Sum of all entries' errors\n",
    "        del_w = error_terms.sum(axis=0)\n",
    "                       \n",
    "        # Update the weights here. The learning rate times the \n",
    "        # change in weights\n",
    "        # don't have to divide by n_records since it is compensated by the learning rate        \n",
    "        weights += learnrate * del_w / n_records  \n",
    "\n",
    "        # Printing out the mean square error on the training set\n",
    "        if e % (epochs / 10) == 0:            \n",
    "            loss = np.mean(error_formula(targets, outputs))\n",
    "            print(\"Epoch:\", e)\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            print(\"=========\")\n",
    "    print(\"Finished training!\")\n",
    "    return weights\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss:  0.7493887438467536\n",
      "=========\n",
      "Epoch: 100\n",
      "Train loss:  0.7484518251963341\n",
      "=========\n",
      "Epoch: 200\n",
      "Train loss:  0.747521680408004\n",
      "=========\n",
      "Epoch: 300\n",
      "Train loss:  0.7465982641498909\n",
      "=========\n",
      "Epoch: 400\n",
      "Train loss:  0.7456815313032333\n",
      "=========\n",
      "Epoch: 500\n",
      "Train loss:  0.7447714369630561\n",
      "=========\n",
      "Epoch: 600\n",
      "Train loss:  0.7438679364388138\n",
      "=========\n",
      "Epoch: 700\n",
      "Train loss:  0.7429709852549953\n",
      "=========\n",
      "Epoch: 800\n",
      "Train loss:  0.7420805391516935\n",
      "=========\n",
      "Epoch: 900\n",
      "Train loss:  0.7411965540851397\n",
      "=========\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "weights = train_nn(features.to_numpy(), targets.to_numpy(), epochs, learnrate, error_term_formula, error_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train loss:  0.2766699107638816\n",
      "=========\n",
      "Epoch: 100\n",
      "Train loss:  0.27656584547570645\n",
      "=========\n",
      "Epoch: 200\n",
      "Train loss:  0.2764619284745197\n",
      "=========\n",
      "Epoch: 300\n",
      "Train loss:  0.2763581596838675\n",
      "=========\n",
      "Epoch: 400\n",
      "Train loss:  0.27625453902674174\n",
      "=========\n",
      "Epoch: 500\n",
      "Train loss:  0.2761510664255828\n",
      "=========\n",
      "Epoch: 600\n",
      "Train loss:  0.27604774180228203\n",
      "=========\n",
      "Epoch: 700\n",
      "Train loss:  0.2759445650781837\n",
      "=========\n",
      "Epoch: 800\n",
      "Train loss:  0.27584153617408774\n",
      "=========\n",
      "Epoch: 900\n",
      "Train loss:  0.27573865501025163\n",
      "=========\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "weights = train_nn(features.to_numpy(), targets.to_numpy(), epochs, learnrate, error_term_formula_mse, error_formula_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Accuracy on the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.650\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test data\n",
    "test_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = test_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:debug-env]",
   "language": "python",
   "name": "conda-env-debug-env-xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}